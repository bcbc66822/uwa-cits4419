//Need to consider exponential back off limit for initiating new route discoveries
//Keep broken routes in cache for certain time? So that broken link request wont be forwarded
//How long to keep cached routes for?
//Shortening of routes by gratious reply?
//Piggyback route error msgs on a node's new route request.
//TOBE IMPLEMENTED IN PYTHON



Dsr protocol 
{
	initialize Route Cache
	initialize Address table
	initialize Msg id table
	initialize Msg buffer
	timelimit = xxx
	exponetial backoff time = 0
	hop_limit = 3
	max_num_retransmission = 5
	
	while (true)
	{
		process_msg_buffer()
		Scan_medium_for_msg
		if got_msg()
		{
			switch (msg)
				case : is_route_request(msg)
					do routerequest(msg)
				case : is_route_reply(msg)
					do routereply(msg, msg.route, false)
				case : is_data_packet(msg)
					do deliverdata(msg, msg.route)
				case : is_route_error(msg)
					do route_error(msg, false)
				case : other_data_packet(msg)
					do routemaintennce(msg.route)					
		}
		do routemaintennce(msg.route)
	}


}

process_msg_buffer()
{
	if Msg buffer not empty
	{
		loop_through(msg_buffer)
		{
			cur_msg = msg buffer.first
			if cur_msg.timeinbuffer > timelimit
			{
				msg buffer.remove(first)
			}
		}
		
		msg = msg buffer.remove(first)
		dest = msg.destination
		if route_cache_contains(dest)
		{
			route = route_cache_finds(dest)
			do forward(msg, route)
		}
		else
		{
			do route_discovery(msg)
		}
	}
	
}

route_discovery(msg)
{
	// do something regarding exponetial back off
	//to limit how fast new route discovery is performed for 'old' messages in buffer
	request_msg = new route_request(msg, dest)
	request_msg.hopcount = 0
	request_msg.hoplimit = hop_limit
	broadcast(request_msg,request)
}

routerequest(msg)
{	
	do routemaintennce(msg.route)	
	
	if msg.destination is me
	{
		do routereply(msg, empty, false)
	}
	else
	if msg.sourceroute(contains me)
	{
		discard msg
	}
	else
	if msg_id_table_contains(msg.id)
	{
		discard msg
	}
	else
	if msg.hop_count > msg.hop_limit
	{
		discard msg
	}
	else
	if route_cache_contains(msg.destination)
	{
		route = route_cache_finds(dest)
		do routereply(msg, route, true)
	}
	else
	{
		msg.route_add(my_address)
		msg.hop_count_increment()
		broadcast(msg,request)	
	}
}

routereply(msg, route, fromcache)
{
	//Need some sort of delay to limit how fast a route reply is sent back
	//To prevent a route reply storm
	Scan_medium_for_msg
	if got_msg() and is_data_packet(new_msg)
	{
		if new_msg.dest = msg.dest && new_msg.source = msg.source
		{
			//Dont send route reply as the initiator have received a (possible shorter)
			//route reply and is transmitting the intended packet
		}
		else
		{
			if route.empty
			{
				route = msg.sourceroute.reverse
				reply_msg = new route_reply(msg,route)
				forward(reply_msg, route)
			}
			else
			{
				if fromcache
				{
					route = route.reverse + msg.sourceroute.reverse
				}
				reply_msg = new route_reply(msg,route)
				forward(reply_msg, route)
			}
		}
	}				
}

route_error(msg, issource)
{
	if issource
	{
		broken_link = determine_broken_link(msg)
		route_cache_remove(broken_link)
		error_msg = new error_msg(broken_link)
		broadcast(error_msg, error)
	}
	else
	{
		broken_link = determine_broken_link(msg)
		route_cache_remove(broken_link)
		broadcast(msg, error)
	}
	if msg.iniator_address = me
	{
		loop_through_msg_buffer
		
	}
}

deliverdata(msg, route)
{
	if msg.dest = me
	{
		send to application layer
	}
	else
	{
		num_times_transmitted = 0;
		while (num_times_transmitted < max_num_retransmission)
		{
			forward(msg, route)
			Scan_medium_for_msg
			if received_ack
			{
				break
			}
			else
			{
				num_times_transmitted++
			}
		}
		if (num_times_transmitted > max_num_retransmission)
		{
			route_error(msg, true)
		}
	}
}

routemaintennce(route)	
{
}